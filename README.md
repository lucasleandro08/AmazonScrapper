# üõí Amazon Product Scraper

**Sistema Full-Stack de Web Scraping com Clean Code**

Sistema completo de web scraping para extrair informa√ß√µes de produtos da Amazon Brasil. Desenvolvido com **Bun**, **Express**, **Vite** e **Vanilla JavaScript**, seguindo princ√≠pios de **Clean Code** e arquitetura modular.

## ‚ú® Principais Caracter√≠sticas

| üé® Interface Moderna | ‚ö° Performance Otimizada | üõ°Ô∏è Tratamento de Erros | üßπ Clean Architecture |
|---|---|---|---|
| Design responsivo com tema Amazon | Cache inteligente e rate limiting | Gerenciamento robusto com fallbacks | Separa√ß√£o clara de responsabilidades |

## üõ†Ô∏è Stack Tecnol√≥gica

### Backend
![Bun](https://img.shields.io/badge/Bun-000000?style=flat&logo=bun&logoColor=white)
![Express.js](https://img.shields.io/badge/Express.js-404D59?style=flat&logo=express&logoColor=white)
![Axios](https://img.shields.io/badge/Axios-5A29E4?style=flat&logo=axios&logoColor=white)
![JSDOM](https://img.shields.io/badge/JSDOM-E34F26?style=flat&logoColor=white)

### Frontend
![Vite](https://img.shields.io/badge/Vite-646CFF?style=flat&logo=vite&logoColor=white)
![JavaScript](https://img.shields.io/badge/JavaScript-F7DF1E?style=flat&logo=javascript&logoColor=black)
![CSS3](https://img.shields.io/badge/CSS3-1572B6?style=flat&logo=css3&logoColor=white)
![HTML5](https://img.shields.io/badge/HTML5-E34F26?style=flat&logo=html5&logoColor=white)

## üöÄ Instala√ß√£o e Execu√ß√£o

> **Pr√©-requisitos:** Bun >= 1.0.0, Node.js >= 18.0.0, npm

### 1. Clone o Reposit√≥rio

git clone <repository-url>
cd AmazonScraper

text

### 2. Configura√ß√£o do Backend

cd backend
npm i --save

text

### 3. Configura√ß√£o do Frontend

cd ../frontend
npm i --save

text

### 4. Execu√ß√£o

Terminal 1 - Backend
cd backend
bun server.js

Terminal 2 - Frontend
cd frontend
npm run dev

Acesse: http://localhost:5173
text

## üèóÔ∏è Arquitetura

### Clean Code Principles Aplicados:

- **Single Responsibility:** Cada classe/m√≥dulo tem uma fun√ß√£o espec√≠fica
- **Separation of Concerns:** Controllers ‚Üí Services ‚Üí Utils
- **Error Handling:** Middleware centralizado com tratamento espec√≠fico
- **Modularity:** C√≥digo reutiliz√°vel e facilmente test√°vel

### Estrutura do Projeto:

amazon-scraper/
‚îú‚îÄ‚îÄ backend/
‚îÇ ‚îú‚îÄ‚îÄ src/
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ controllers/ # HTTP request handling
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ services/ # Business logic & scraping
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ utils/ # Error handling & helpers
‚îÇ ‚îú‚îÄ‚îÄ package.json
‚îÇ ‚îî‚îÄ‚îÄ server.js
‚îî‚îÄ‚îÄ frontend/
‚îú‚îÄ‚îÄ src/
‚îÇ ‚îú‚îÄ‚îÄ js/ # Client-side logic
‚îÇ ‚îú‚îÄ‚îÄ css/ # Responsive styling
‚îÇ ‚îî‚îÄ‚îÄ index.html # Main interface
‚îú‚îÄ‚îÄ package.json
‚îî‚îÄ‚îÄ vite.config.js

text

## üîó API Endpoints

### GET /api/scrape

**Par√¢metro:** `keyword` (string, obrigat√≥rio)

curl "http://localhost:3000/api/scrape?keyword=notebook"

text

**Response:**
{
"success": true,
"keyword": "notebook",
"totalProducts": 16,
"products": [
{
"title": "Notebook Dell Inspiron 15",
"rating": 4.3,
"reviewCount": 1250,
"imageURL": "https://...",
"price": "R$ 2.499,00"
}
],
"cached": false
}

text

## ‚öôÔ∏è Funcionalidades T√©cnicas

- **Cache Inteligente:** 5 minutos de cache para evitar requisi√ß√µes desnecess√°rias
- **Rate Limiting:** 10 segundos m√≠nimos entre buscas diferentes
- **User-Agent Rotation:** 6 User-Agents diferentes para evitar detec√ß√£o
- **Multiple Selectors:** Fallbacks para diferentes layouts da Amazon
- **Error Recovery:** Tratamento espec√≠fico para 503, 429 e ECONNREFUSED

## ‚ö†Ô∏è Desafios e Solu√ß√µes

> **Principal Desafio:** Sistema anti-bot da Amazon (erro 503)  
> **Solu√ß√£o:** Headers real√≠sticos + delays inteligentes + rota√ß√£o de User-Agents + cache
- Bloqueios tempor√°rios ‚Üí Sistema de cache e rate limiting

## üí° Como Usar

1. Acesse `http://localhost:5173`
2. Digite uma palavra-chave (ex: "notebook", "mouse")
3. Clique em "Buscar" e aguarde o processamento
4. Visualize os produtos com t√≠tulo, rating, avalia√ß√µes, imagem e pre√ßo

> **Nota:** A Amazon pode bloquear temporariamente ap√≥s v√°rias buscas. Isso √© comportamento normal e esperado para sistemas de scraping.
